{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TECH Challenge\n",
    "# Enunciado\n",
    "Imagine agora, que você vai atuar como Expert em Data Analytics em uma empresa que exporta vinhos do Brasil para o mundo todo.\n",
    "Sua área é recém-criada dentro da empresa, e você será responsável pelos relatórios iniciais a serem apresentados em uma reunião de investidores e acionistas, explicando a quantidade de vinhos exportados e os fatores externos que podem vir a surgir e que interferem nas análises:\n",
    "1. Dados climáticos.\n",
    "2. Dados demográficos.\n",
    "3. Dados econômicos.\n",
    "4. Dados de avaliações de vinhos.\n",
    "\n",
    "O Head de Dados pediu para que você construísse uma tabela contendo as seguintes informações:\n",
    "1. País de origem (Brasil).\n",
    "2. País de destino.\n",
    "3. Quantidade em litros de vinho exportado (utilize: 1KG =1L).\n",
    "4. Valor em US$.\n",
    "\n",
    "Os dados que lhe forneceram são de uma vinícola parceira, e podem ser encontrados aqui: http://vitibrasil.cnpuv.embrapa.br/index.php?opcao=opt_01\n",
    "Seu objetivo é dizer o **montante de venda de exportação nos últimos 15 anos**, separando a análise por país e trazendo quais as prospecções futuras e possíveis ações para uma melhoria nas exportações. \n",
    "\n",
    "\n",
    "Construa gráficos atraentes e que passem a ideia central para que os acionistas e investidores possam seguir em frente com suas ações."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importando bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4 import Tag\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adquirindo os dados\n",
    "Utilizaremos o Beautiful Soup para aquirir os dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contents(elem : Tag) -> str:\n",
    "    '''\n",
    "        Returns the content of the bs4 element as a string.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        elem : bs4.element.Tag        \n",
    "\n",
    "    '''\n",
    "    return str(elem.decode_contents()).strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_page(url: str = \"\", table_class : str = \"\", row_class : str = \"\", row_super_class : str=\"\") -> pd.DataFrame:\n",
    "    '''\n",
    "    Returns the HTML table of the page as a pandas DataFrame.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    url : str\n",
    "        URL of the page\n",
    "    table_class : str\n",
    "        HTML class of the desired table, if applicable\n",
    "    row_class : str\n",
    "        HTML class of the rows\n",
    "    row_super_class : str\n",
    "        HTML class of row categories\n",
    "    ignore_first_column\n",
    "        Ignore first column of returned DataFrame\n",
    "\n",
    "    '''\n",
    "    req = requests.get(url)\n",
    "    soup = BeautifulSoup(req.content, \"html.parser\")\n",
    "    table = soup.find(\"table\", {\"class\":table_class})\n",
    "\n",
    "    columns = ['categoria']\n",
    "    for head in table.find_all('thead'):\n",
    "        for th in head.find_all('th'):\n",
    "            columns += [str(th.decode_contents()).lower().strip()]\n",
    "\n",
    "    category=None\n",
    "    data=[]\n",
    "    for elem in table.find_all('tbody'):\n",
    "        for row in elem.find_all('tr'):\n",
    "            row_counter=0\n",
    "            row_data = []\n",
    "            for item in row.find_all('td'):\n",
    "                content=get_contents(item)\n",
    "                try:\n",
    "                    if row_super_class in item['class'] and row_counter==0:\n",
    "                        category=content\n",
    "                except Exception as e:\n",
    "                    category=None\n",
    "                row_data+=[content]\n",
    "                row_counter+=1\n",
    "            row_data = [category]+row_data\n",
    "            data += [row_data]\n",
    "\n",
    "    return pd.DataFrame(data,columns=columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "req = requests.get(url)\n",
    "soup = BeautifulSoup(req.content, \"html.parser\")\n",
    "timespan = 15\n",
    "last_year = 2024\n",
    "class_table = \"tb_dados\"\n",
    "class_item = \"tb_item\"\n",
    "class_subitem = \"tb_subitem\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:5: SyntaxWarning: invalid escape sequence '\\{'\n",
      "<>:5: SyntaxWarning: invalid escape sequence '\\{'\n",
      "<string>:5: SyntaxWarning: invalid escape sequence '\\{'\n",
      "<>:5: SyntaxWarning: invalid escape sequence '\\{'\n",
      "D:\\Temp\\ipykernel_69512\\1151549546.py:5: SyntaxWarning: invalid escape sequence '\\{'\n",
      "  get_data_from_page(url,class_table,class_subitem,class_item).to_csv(f'extraidos\\{output_prefix}_{year}.csv')\n"
     ]
    }
   ],
   "source": [
    "def get_data_from_timespan(url_front : str=\"\", url_back : str=\"\", last_year : int = 0, years_back : int = 0, class_table : str = \"\", class_item : str=\"\", class_subitem : str=\"\", output_prefix : str=\"\") -> pd.DataFrame:\n",
    "    range_years = range(last_year-years_back,last_year+1)\n",
    "    for year in range_years:\n",
    "        url=f\"{url_front}{year}{url_back}\"\n",
    "        get_data_from_page(url,class_table,class_subitem,class_item).to_csv(f'extraidos\\{output_prefix}_{year}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_b = \"&opcao=opt_06&subopcao=subopt_01\"\n",
    "get_data_from_timespan(url_f, url_b, last_year, timespan, class_table, class_item, class_subitem, output_prefix=\"exportacao_vinhos_mesa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_b = \"&opcao=opt_06&subopcao=subopt_03\"\n",
    "get_data_from_timespan(url_f, url_b, last_year, timespan, class_table, class_item, class_subitem, output_prefix=\"exportacao_uvas_frescas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_b = \"&opcao=opt_06&subopcao=subopt_04\"\n",
    "get_data_from_timespan(url_f, url_b, last_year, timespan, class_table, class_item, class_subitem, output_prefix=\"exportacao_suco_de_uva\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_b = \"&opcao=opt_05&subopcao=subopt_01\"\n",
    "get_data_from_timespan(url_f, url_b, last_year, timespan, class_table, class_item, class_subitem, output_prefix=\"importacao_vinhos_mesa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_b = \"&opcao=opt_05&subopcao=subopt_02\"\n",
    "categoria='importacao'\n",
    "subcategoria='espumantes'\n",
    "get_data_from_timespan(url_f, url_b, last_year, timespan, class_table, class_item, class_subitem, output_prefix=f\"{categoria}_{subcategoria}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_b = \"&opcao=opt_05&subopcao=subopt_03\"\n",
    "subcategoria='uvas_frescas'\n",
    "get_data_from_timespan(url_f, url_b, last_year, timespan, class_table, class_item, class_subitem, output_prefix=f\"{categoria}_{subcategoria}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_b = \"&opcao=opt_05&subopcao=subopt_04\"\n",
    "subcategoria='uvas_passas'\n",
    "get_data_from_timespan(url_f, url_b, last_year, timespan, class_table, class_item, class_subitem, output_prefix=f\"{categoria}_{subcategoria}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_b = \"&opcao=opt_05&subopcao=subopt_05\"\n",
    "subcategoria='suco_de_uva'\n",
    "get_data_from_timespan(url_f, url_b, last_year, timespan, class_table, class_item, class_subitem, output_prefix=f\"{categoria}_{subcategoria}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
